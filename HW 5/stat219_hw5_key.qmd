---
title: "Homework 5"
format:
  pdf:
    fontsize: 12pt
    geometry:
      - inner=1.5cm
      - outer=1.5cm
      - top=2.5cm
      - bottom=2.5cm
    include-in-header:
      - text: |
          \addtokomafont{disposition}{\rmfamily}
          \usepackage{fancyhdr, lastpage, framed, caption, xcolor}
          \captionsetup[figure]{labelformat=empty}
          \pagestyle{fancyplain}
          \fancyhf{}
          \lhead{\fancyplain{}{STAT 0219: Time Series Analysis}}
          \rhead{\fancyplain{}{Stratton - HW4}}
          \fancyfoot[RO, LE] {page \thepage\ of \pageref{LastPage}}
          \thispagestyle{plain}
editor: source
---
<!-- Note: the YAML header is everything above this line. -->
\vspace{-3in}
\textbf{Name:} Your name here  
\textbf{Due:} 2024/10/14
\vspace{1.5in}

Be sure to submit **both** the .pdf and .qmd file to Canvas by Monday, October 14th at 11:59 pm. 

```{r, include = F}
set.seed(10052024)
rm(list = ls())
library(tidyverse)
```

0. [1 pt] With whom did you work on this assignment?

   :::{.callout-warning icon=false appearance="simple"}
   
   :::

1. [ pt] The purpose of this question is to demonstrate that there exist time series structures that Holt-Winters cannot estimate very well. To demonstrate this idea, we are going to simulate data from an AR(2) process with $\alpha_1 = 1.1$ and $\alpha_2 = -.3$. 

   a) [1 pt] Write the hypothetical AR(2) model in proper notation.
   
      :::{.callout-warning icon=false appearance="simple"}
      The model is $x_t = 1.1x_{t-1} - .3x_{t-2} + w_t$, where $\{w_t\}$ is white noise.
      :::   
      
   b) [1 pt] Express the model from part a in terms of the backshift operator. 
   
      :::{.callout-warning icon=false appearance="simple"}
      $(1 - 1.1B + .3B^2)x_t = w_t$
      ::: 
      
   c) [1 pt] Determine whether the model is stationary. 
   
      :::{.callout-warning icon=false appearance="simple"}
      Since the roots both exceed unity in magnitude, the model is stationary. 
      ::: 
      
```{r, indent = "      "}
a <- .3
b <- -1.1
c <- 1

# oldschool 
(-b + c(-1,1)*sqrt(b^2 - 4*a*c))/(2*a)

# or
polyroot(c(c,b,a))
```

   d) [3 pt] Simulate 12 years of monthly data from an AR(2) process with $\alpha_1 = .8$ and $\alpha_2 = -.1$. Convert the synthetic data to a `ts` object and plot the resulting series. 

```{r, indent = "      ", fig.dim = c(6, 4)}
# simulate series
n <- 144
x <- w <- rnorm(n)
for(t in 3:n) x[t] <- 1.1*x[t-1] -.3*x[t-2] + w[t]

# create ts object
x_ts <- ts(
  x,
  start = c(1, 1),
  freq = 12
)
plot(x_ts)
```

   e) [1 pt] Create an ACF plot of the synthetic series and comment what the plot suggests about the autocorrelation.  
   
      :::{.callout-warning icon=false appearance="simple"}
      There is obviously severe autocorrelation that decays over time. 
      ::: 

```{r, indent = "      ", fig.dim = c(6, 3.25)}
acf(x_ts)
```

   f) [1 pt] Create an PACF plot of the synthetic series and comment on what the plot suggests about the autocorrelation.  
   
      :::{.callout-warning icon=false appearance="simple"}
      The PACF plot makes it clear that there is massive autocorrelation at lag 1, and strong negative autocorrelation at lag 2. 
      ::: 

```{r, indent = "      ", fig.dim = c(6, 3.25)}
pacf(x_ts)
```

   g) [2 pt] Fit a Holt-Winters model to the synthetic series and plot the results. 
  
```{r, indent = "      ", fig.dim = c(6, 4)}
hw <- HoltWinters(x_ts)
plot(hw)
```

   h) [2 pt] Create an ACF plot of the residuals from the Holt-Winters model and comment on whether the model has accounted for the residual autocorrelation. 
   
      :::{.callout-warning icon=false appearance="simple"}
      It has not! Lots of autocorrelation left. 
      ::: 

```{r, indent = "      ", fig.dim = c(6, 4)}
acf(resid(hw))
```

\newpage

2. [2 pt] Using the characteristic equation, show that a random walk is not stationary. 

   :::{.callout-warning icon=false appearance="simple"}
   Recall that a random walk is given by $x_t = x_{t-1} + w_t$, which can be written as $(1 - B)x_t = w_t$. The characteristic equation for this model has root $B = 1$, which does not exceed unity. Therefore, the random walk is not stationary. 
   :::

3. [3 pt] Determine for what values of $\alpha$ an AR(1) process is stationary. 

   :::{.callout-warning icon=false appearance="simple"}
   This is another characteristic equation question. Recall that an AR(1) process is
   $$
   \begin{split}
   x_t &= \alpha x_{t-1} + w_t \\
   x_t - \alpha B x_t &= w_t \\
   (1 - \alpha B)x_t = w_t
   \end{split}
   $$
   The characteristic equation for an AR(1) process is
   $$
   1 - \alpha B = 0
   $$
   which has a root of $\frac{1}{\alpha}$. In order for the model to be stationary, the root must exceed unity in magnitude. Therefore $-1 < \alpha < 1$ results in a stationary model. 
   :::

4. [6 pt] The purpose of this question is to prove one of the second order properties of an AR(1) process. 

   a) [1 pt] Express an AR(1) process in terms of the backshift operator.  

      :::{.callout-warning icon=false appearance="simple"}
      From question 3, $(1 - \alpha B)x_t = w_t$.
      :::
      
   b) [3 pt] Using the expression from part a, show that $x_t = \sum_{i=0}^\infty \alpha^i w_{t-i}$. It is likely helpful to know that $(1-B)^{-1} = 1 + B + B^2 + \dots$ by Binomial expansion.

      :::{.callout-warning icon=false appearance="simple"}
      From question 3, $(1 - \alpha B)x_t = w_t$, which implies that $x_t = (1 - \alpha B)^{-1}w_t$. By the handy hint I provided
      $$
      \begin{split}
      x_t &= (1 - \alpha B)^{-1}w_t \\
      &= (1 + \alpha B + \alpha B^2 + \dots)w_t \\
      &= w_t + \alpha B w_t + \alpha B^2 w_t + \dots \\
      &= w_t + \alpha w_{t-1} + \alpha w_{t-2} + \dots \\
      &= \sum_{i=0}^\infty \alpha^i w_{t-i}
      \end{split}
      $$
      :::
      
   c) [2 pt] Using the expression from part b, show that the $E(x_t) = 0$. Recall that $E\left( \sum_{i=1}^n X_i \right) = \sum_{i=1}^n E(X_i)$ and that $E(cX) = cE(X)$ if $c$ is a constant. 

      :::{.callout-warning icon=false appearance="simple"}
      We just plug it in. 
      $$
      E(x_t) = E \left(\sum_{i=0}^\infty \alpha^i w_{t-i} \right) = \sum_{i=0}^\infty \alpha^i E(w_{t-i}) = 0
      $$
      The last equality follows from the fact that $\{w_t\}$ is white noise.
      :::

