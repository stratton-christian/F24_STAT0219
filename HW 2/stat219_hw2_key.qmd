---
title: "Homework 2"
format:
  pdf:
    fontsize: 12pt
    geometry:
      - inner=1.5cm
      - outer=1.5cm
      - top=2.5cm
      - bottom=2.5cm
    include-in-header:
      - text: |
          \addtokomafont{disposition}{\rmfamily}
          \usepackage{fancyhdr, lastpage, framed, caption, xcolor}
          \captionsetup[figure]{labelformat=empty}
          \pagestyle{fancyplain}
          \fancyhf{}
          \lhead{\fancyplain{}{STAT 0219: Time Series Analysis}}
          \rhead{\fancyplain{}{Stratton - HW2}}
          \fancyfoot[RO, LE] {page \thepage\ of \pageref{LastPage}}
          \thispagestyle{plain}
editor: source
---
<!-- Note: the YAML header is everything above this line. -->
\vspace{-3in}
\textbf{Name:} Your name here  
\textbf{Due:} 2024/09/23
\vspace{1.5in}

Be sure to submit **both** the .pdf and .qmd file to Canvas by Monday, September 23rd at 11:59 pm. 

```{r, include = F}
rm(list = ls())
library(tidyverse)
```

0. [1 pt] Did you work with anyone on this homework? If so, who?

   :::{.callout-warning icon=false appearance="simple"}
   
   :::

1. [13 pt] For this homework, we continue practicing decomposition of time series, again recreating the output of `decompose`, but this time focusing on a multiplicative decomposition model. 

   a) [1 pt] Load the `AirPassengers` data set.

```{r, indent = "      ", eval = T, echo = T, warning = F, message = F}
data(AirPassengers)
ap <- AirPassengers
```

   b) [1 pt] Plot the raw `AirPassengers` time series and describe what you see in terms of trend and seasonal effect. 
   
```{r, indent = "      ", eval = T, echo = T, warning = F, message = F, fig.dim = c(6, 3), fig.align = 'center'}
plot(ap)
```   

      :::{.callout-warning icon=false appearance="simple"}
      The series has a strong positive trend and an equally strong seasonal component that increases in magnitude as the trend increases.
      :::

   c) [1 pt] Is an additive decomposition model appropriate for these data? Why or why not?
   
      :::{.callout-warning icon=false appearance="simple"}
      No. The magnitude of the seasonal effect increases as the trend increases, suggesting a multiplicative model would be more appropriate.
      :::
   
   d) [1 pt] Regardless of your answer to the previous question, fit a multiplicative decomposition model to the `AirPassengers` data set and plot the results.  

```{r, indent = "      ", fig.dim = c(6, 6)}
ap_decompose <- decompose(ap, type = "multiplicative")
plot(ap_decompose)
```

   e) [3 pt] Calculate the trend component for the multiplicative model by hand, and compare your estimated trend effects to those obtained by `decompose` to ensure they are correct. 
   
```{r, indent = "      "}
ap_trend <- matrix(NA, nrow = length(ap) - 12, ncol = 1)
for(t in 7:(length(ap)-6)){
  ap_trend[t-6,] <- (
    .5*ap[t-6] + ap[t-5] + ap[t-4] + ap[t-3] + 
      ap[t-2] + ap[t-1] + ap[t] + ap[t+1] + 
      ap[t+2] + ap[t+3] + ap[t+4] + ap[t+5] + .5*ap[t+6]
  )*(1/12)
}

# append the NAs we skipped
ap_trend_full <- c(rep(NA, 6), ap_trend, rep(NA, 6))

# check if hand values are equal, up to numeric tolerance
all(abs(ap_trend_full - ap_decompose$trend) <= 1e-10, na.rm = T)
```

   f) [3 pt] Calculate the average seasonal effect associated with each month and center the resulting estimates. Compare these 12 values to those obtained from the `decompose` function to ensure you have calculated them correctly.
   
```{r, indent = "      "}
s_hat <- ap / ap_trend_full
s_bar_tmp <- colMeans(matrix(s_hat, ncol = 12, byrow = T), na.rm = T)
s_bar <- s_bar_tmp/mean(s_bar_tmp)

# check if hand values are equal, up to numeric tolerance
all(abs(s_bar - ap_decompose$figure) <= 1e-10)
```   
   
   i) [3 pt] Calculate the residual error series from the previously created objects representing the trend and seasonal effects. Compare the by-hand calculation to the results from `decompose` to ensure that you have calculated the series correctly. 
      
```{r, indent = "      "}
# calculate residual error series
res <- ap / (ap_trend_full * s_bar)

# check if hand values are equal, up to numeric tolerance
all(abs(res - ap_decompose$random) <= 1e-10, na.rm = T)
```      

\newpage

2. [5 pt] The moving average calculated by the `decompose` function is a type of **smoother** or **filter**. Smoothing/filtering algorithms generally seek to predict a response at time $t$ based on observations from both before and after $t$, as we saw with the moving average in question 1. Another popular smoother is the **loess** smoother, which stands for locally estimated scatterplot smoothing, and can be performed in R with the `stl` function. 

   a) [2 pt] The following code fits a loess smoother to the `AirPassengers` data and prints the trend estimate. How does this compare to the trend created by `decompose`? Do you notice any major differences?
   
```{r, indent = "      ", warning = F, message = F}
loess_periodic <- stl(ap, s.window = "periodic")
plot(loess_periodic)
loess_periodic$time.series[,2]
```

      :::{.callout-warning icon=false appearance="simple"}
      The values differ by a little, and you are able to obtain trend estimates for the first and last 6 months.
      :::

   b) [2 pt] The code above assumes the window for calculating the loess smoother is based on the period of the time series. Play around with changing the `s.window` argument (which can be an integer) in the `stl` function. What do you notice about the resulting decomposition?
   
      :::{.callout-warning icon=false appearance="simple"}
      Changing the values can have a fairly significant impact on the magnitude of the estimate of the seasonal component. 
      :::

```{r, indent = "      ", warning = F, message = F, fig.dim = c(6, 6), fig.align='center'}
plot(stl(ap, s.window = 3))
```

```{r, indent = "      ",warning = F, message = F, fig.dim = c(6, 6), fig.align='center'}
plot(stl(ap, s.window = 10))
```

```{r, indent = "      ",warning = F, message = F, fig.dim = c(6, 6), fig.align='center'}
plot(stl(ap, s.window = 30))
```

   c) [1 pt] The smoothing and filtering algorithms provide a nice way to summarize a time series in retrospect. Can you think of a shortcoming for using these tools to estimate time series and create forecasts? 

      :::{.callout-warning icon=false appearance="simple"}
      You cannot create forecasts with them! They rely on data from time points both before and after the point of prediction, meaning you cannot forecast into the future with them. Generally, they do not provide a model that you can write down to perform forecasts.
      :::

3. [6 pt] Find an interesting **discrete** time series data set and create a decomposition of it below. Note that [Kaggle](https://www.kaggle.com/datasets) and [Data.world](https://data.world/datasets/open-data) often provide some nicely manicured, free data. 


